{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#import subprocess\n",
    "\n",
    "#subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pandas\", \"numpy\", \"statsmodels\", \"matplotlib\", \"scipy\", \"openpyxl\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Load the cleaning function we created last time\n",
    "2) Use the function to prepare the SPX and NVDA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use this cleaning function we created last time\n",
    "def data_cleaning(benchm, asset):\n",
    "\n",
    "    benchm[\"Date\"] = pd.to_datetime(benchm[\"Date\"])\n",
    "    benchm = benchm.sort_values(by='Date', ascending=True) \n",
    "\n",
    "    asset[\"Date\"] = pd.to_datetime(asset[\"Date\"])\n",
    "    asset = asset.sort_values(by='Date', ascending=True) \n",
    "\n",
    "    comb = benchm.merge(asset,on=\"Date\", how=\"left\")\n",
    "\n",
    "    comb['return_benchmark'] = comb.iloc[:, 1] / comb.iloc[:, 1].shift(1)-1\n",
    "    comb['return_asset'] = comb.iloc[:, 2] / comb.iloc[:, 2].shift(1)-1\n",
    "    #comb['logreturn_benchmark'] = np.log(comb.iloc[:, 1] / comb.iloc[:, 1].shift(1))\n",
    "    #comb['logreturn_asset'] = np.log(comb.iloc[:, 2] / comb.iloc[:, 2].shift(1))\n",
    "    comb = comb.dropna()\n",
    "\n",
    "    return comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Load the Fama-French 5-factor (FF5) time-series data\n",
    "4) Format the dates to datetime format\n",
    "5) Merge the SPX/NVDA data and the FF5 data using the SPX/NVDA dataframe as the leading dataframe\n",
    "6) Compute excess returns for NVDA by subtracting the risk-free rate (column \"RF\" in FF5) from simple NVDA returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Regress NVDA excess returns on a constant and all 5 Fama-French factors (\"Mkt-RF\", \"SMB\", \"HML\", \"RMW\", \"CMA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FED Probit model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Load the dataset containing the difference between the 3-month and 10-year Treasury yield (t10y3m)\n",
    "2) Ensure the dates are in datetime format and create a new column that contains the first date of the month to use it as a month indicator\n",
    "3) Group data by that month indicator taking the monthly mean of the yield spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Load the dataset with monthly recession indicators and ensure the date column is in datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Merge the two dataframes using on the month indicator the yield spread as the leading dataframe\n",
    "6) Create a new column that gives the 12 months ahead recession indicator using the .shift() method\n",
    "7) Drop NaN observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Estimate a probit model with an intercept, the yield spread as an independent variable and 12 month ahead recession indicator as the dependent variable using data until December 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Based on this model, predict the probability of a recession for each month in the entire dataset and plot that probability over time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
