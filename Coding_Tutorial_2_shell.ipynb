{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T21:09:21.202308Z",
     "start_time": "2025-10-10T21:09:21.199658Z"
    }
   },
   "source": [
    "#import sys\n",
    "#import subprocess\n",
    "\n",
    "#subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pandas\", \"numpy\", \"statsmodels\", \"matplotlib\", \"scipy\", \"openpyxl\"])"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T21:09:46.973092Z",
     "start_time": "2025-10-10T21:09:27.303498Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Load the cleaning function we created last time\n",
    "2) Use the function to prepare the SPX and NVDA data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T21:10:08.419204Z",
     "start_time": "2025-10-10T21:10:08.415823Z"
    }
   },
   "source": [
    "# you can use this cleaning function we created last time\n",
    "def data_cleaning(benchm, asset):\n",
    "\n",
    "    benchm[\"Date\"] = pd.to_datetime(benchm[\"Date\"])\n",
    "    benchm = benchm.sort_values(by='Date', ascending=True) \n",
    "\n",
    "    asset[\"Date\"] = pd.to_datetime(asset[\"Date\"])\n",
    "    asset = asset.sort_values(by='Date', ascending=True) \n",
    "\n",
    "    comb = benchm.merge(asset,on=\"Date\", how=\"left\")\n",
    "\n",
    "    comb['return_benchmark'] = comb.iloc[:, 1] / comb.iloc[:, 1].shift(1)-1\n",
    "    comb['return_asset'] = comb.iloc[:, 2] / comb.iloc[:, 2].shift(1)-1\n",
    "    #comb['logreturn_benchmark'] = np.log(comb.iloc[:, 1] / comb.iloc[:, 1].shift(1))\n",
    "    #comb['logreturn_asset'] = np.log(comb.iloc[:, 2] / comb.iloc[:, 2].shift(1))\n",
    "    comb = comb.dropna()\n",
    "\n",
    "    return comb"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Load the Fama-French 5-factor (FF5) time-series data\n",
    "4) Format the dates to datetime format\n",
    "5) Merge the SPX/NVDA data and the FF5 data using the SPX/NVDA dataframe as the leading dataframe\n",
    "6) Compute excess returns for NVDA by subtracting the risk-free rate (column \"RF\" in FF5) from simple NVDA returns"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T21:49:51.612198Z",
     "start_time": "2025-10-10T21:49:51.167132Z"
    }
   },
   "source": [
    "FF5 = pd.read_excel(\"F-F_Research_Data_5_Factors_2x3_daily.xlsx\")\n",
    "FF5[\"Date\"] = pd.to_datetime(FF5[\"Date\"])\n",
    "print(FF5.head())\n",
    "\n",
    "df = pd.read_excel(\"SPX.xlsx\")\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df = df.sort_values(\"Date\")\n",
    "\n",
    "dfNV = pd.read_excel(\"NVDA.xlsx\")\n",
    "dfNV[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "dfNV = dfNV.sort_values(\"Date\")\n",
    "\n",
    "print(df.head())\n",
    "print(dfNV.head())\n",
    "\n",
    "\n",
    "df = df.merge(dfNV, how=\"left\", on=\"Date\")\n",
    "\n",
    "df[\"returnsSPX\"] = (df[\"SPX\"] / df[\"SPX\"].shift(1)) -1\n",
    "df[\"returnsNV\"] = (df[\"NVDA\"] / df[\"NVDA\"].shift(1)) -1\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "df = df.merge(FF5, how= \"left\", on=\"Date\")\n",
    "\n",
    "df.to_csv(\"test.csv\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Date  Mkt-RF   SMB   HML   RMW   CMA    RF\n",
      "0 1970-01-01 00:00:00.019630701   -0.67  0.00 -0.34 -0.01  0.16  0.01\n",
      "1 1970-01-01 00:00:00.019630702    0.79 -0.26  0.26 -0.07 -0.20  0.01\n",
      "2 1970-01-01 00:00:00.019630703    0.63 -0.17 -0.09  0.18 -0.34  0.01\n",
      "3 1970-01-01 00:00:00.019630705    0.40  0.08 -0.27  0.09 -0.34  0.01\n",
      "4 1970-01-01 00:00:00.019630708   -0.63  0.04 -0.18 -0.29  0.14  0.01\n",
      "        Date      SPX\n",
      "0 2023-01-03  3824.14\n",
      "1 2023-01-04  3852.97\n",
      "2 2023-01-05  3808.10\n",
      "3 2023-01-06  3895.08\n",
      "4 2023-01-09  3892.09\n",
      "        Date    NVDA\n",
      "0 2023-01-03  14.614\n",
      "1 2023-01-04  14.315\n",
      "2 2023-01-05  14.749\n",
      "3 2023-01-06  14.265\n",
      "4 2023-01-09  14.859\n",
      "        Date      SPX    NVDA  returnsSPX  returnsNV\n",
      "1 2023-01-04  3852.97  14.315    0.007539  -0.020460\n",
      "2 2023-01-05  3808.10  14.749   -0.011646   0.030318\n",
      "3 2023-01-06  3895.08  14.265    0.022841  -0.032816\n",
      "4 2023-01-09  3892.09  14.859   -0.000768   0.041640\n",
      "5 2023-01-10  3919.25  15.628    0.006978   0.051753\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Regress NVDA excess returns on a constant and all 5 Fama-French factors (\"Mkt-RF\", \"SMB\", \"HML\", \"RMW\", \"CMA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FED Probit model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Load the dataset containing the difference between the 3-month and 10-year Treasury yield (t10y3m)\n",
    "2) Ensure the dates are in datetime format and create a new column that contains the first date of the month to use it as a month indicator\n",
    "3) Group data by that month indicator taking the monthly mean of the yield spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Load the dataset with monthly recession indicators and ensure the date column is in datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Merge the two dataframes using on the month indicator the yield spread as the leading dataframe\n",
    "6) Create a new column that gives the 12 months ahead recession indicator using the .shift() method\n",
    "7) Drop NaN observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Estimate a probit model with an intercept, the yield spread as an independent variable and 12 month ahead recession indicator as the dependent variable using data until December 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Based on this model, predict the probability of a recession for each month in the entire dataset and plot that probability over time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
